{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f138339b6459460a",
   "metadata": {},
   "source": [
    "## Neural Network and Deep Neural Network\n",
    "\n",
    "Neural Network는 Layer가 두 개 이상인 모형을 의미한다. Layer가 심층적으로 쌓인 경우, Deep Neural Network라고 한다\n",
    "\n",
    "<center>\n",
    "\n",
    "![nn.png](Image/neural.png)\n",
    "\n",
    "</center>\n",
    "\n",
    "Neural Network에서는 계수(Coefficient)보다는 가중치(Weights)로 더 많이 통용된다. 추정하는 가중치 parameter는 결국 선형모형에서 Coefficient를 추정하는것과 같다.\n",
    "\n",
    "**활성화 함수(Activation Function)** 는 통계학에서의 연결 함수의 개념을 차용한 것이다. \n",
    "\n",
    "대표적인 연결 함수로는 log, sigmoid, logistic이 존재하는데, 이중 sigmoid와 logistic은 초창기 Neural Network model의 활성화 함수로 사용된 것이다\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b5657dcd844d8f",
   "metadata": {},
   "source": [
    "#### 1. Input Layers\n",
    "\n",
    "입력층에서는 데이터의 특성들이 입력된다. 입력 벡터 $\\mathbf{x} = [x_1, x_2, ..., x_n]$는 특성 공간에서의 값들을 나타낸다. 입력값 $x_i$는 첫 번째 은닉층으로 전달된다.\n",
    "\n",
    "$$\\mathbf{x} = [x_1, x_2, ..., x_n]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ef1c2fa6816c20",
   "metadata": {},
   "source": [
    "#### 2. Hidden Layer\n",
    "\n",
    "은닉층은 입력값에 가중치(weight)를 곱하고, 그 결과에 **편향(bias)** 을 더한 후 **활성화 함수(activation function)** 를 적용하여 비선형성을 도입한다.\n",
    "\n",
    "입력 벡터 $\\mathbf{x}$가 은닉층으로 전달되며, 가중치 행렬 $\\mathbf{W}^{(1)}$와 곱해진다. 이 때, $\\mathbf{W}^{(1)}$는 입력층에서 은닉층으로의 가중치 행렬이다. 각 은닉층 노드 $h_j$에서의 계산은 다음과 같다.\n",
    "\n",
    "$$h_j = f\\left( \\sum_{i=1}^{n} W_{ji}^{(1)} x_i + b_j^{(1)} \\right)$$\n",
    "\n",
    "여기서 $W_{ji}^{(1)}$는 입력 $x_i$에서 은닉층 뉴런 $h_j$로 가는 가중치, $b_j^{(1)}$는 은닉층 뉴런 $h_j$의 bias(y intercept)이며, $f$는 비선형 활성화 함수(ex. sigmoid, ReLU 등)이다. 통계학에서 활성화함수는 대개 연결 함수를 의미한다. 따라서 은닉층의 출력 벡터 $\\mathbf{h}^{(1)}$는 다음과 같다.\n",
    "\n",
    "$$\\mathbf{h}^{(1)} = f\\left( \\mathbf{W}^{(1)} \\mathbf{x} + \\mathbf{b}^{(1)} \\right)$$\n",
    "\n",
    "여기서 $\\mathbf{W}^{(1)}$는 은닉층의 가중치 행렬, $\\mathbf{b}^{(1)}$는 은닉층의 편향 벡터이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad443171656c19b5",
   "metadata": {},
   "source": [
    "### 3. Output Layer\n",
    "\n",
    "출력층도 은닉층과 동일하게 가중치와 편향을 사용하여 계산된다. 은닉층에서 계산된 값들을 출력층으로 전달하여 최종 예측을 생성한다.\n",
    "\n",
    "은닉층의 출력값 $\\mathbf{h}^{(1)}$는 출력층으로 전달된다. 출력층에서 각 출력 노드 $y_k$에 대한 계산은 다음과 같다\n",
    "\n",
    "$$y_k = f\\left( \\sum_{j=1}^{m} W_{kj}^{(2)} h_j^{(1)} + b_k^{(2)} \\right)$$\n",
    "\n",
    "여기서 $W_{kj}^{(2)}$는 은닉층 노드 $h_j^{(1)}$에서 출력층 노드 $y_k$로 가는 가중치, $b_k^{(2)}$는 출력층 노드 $y_k$의 bias이고 $f$는 출력층에서 사용하는 활성화 함수이다. 출력층에서의 출력 벡터 $\\mathbf{y}$는 다음과 같이 표현된다\n",
    "\n",
    "$$\\mathbf{y} = f\\left( \\mathbf{W}^{(2)} \\mathbf{h}^{(1)} + \\mathbf{b}^{(2)} \\right)$$\n",
    "\n",
    "여기서 $\\mathbf{W}^{(2)}$는 출력층의 가중치 행렬, $\\mathbf{b}^{(2)}$는 출력층의 편향 벡터이다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef32af2c72d0c1ce",
   "metadata": {},
   "source": [
    "#### 4. Loss Function\n",
    "\n",
    "모델이 예측한 값과 실제 값 사이의 차이를 평가하기 위해 손실 함수가 사용된다. 분류 문제에서는 **교차 엔트로피(cross-entropy)** 가 자주 사용되고, 회귀 문제에서는 **평균 제곱 오차(mean squared error, MSE)** 가 주로 사용된다. 교차 엔트로피 손실 함수는 다음과 같다.\n",
    "\n",
    "$$L(\\mathbf{y}, \\hat{\\mathbf{y}}) = - \\sum_{k} y_k \\log(\\hat{y_k})$$\n",
    "\n",
    "여기서 $y_k$는 실제 클래스 label, $\\hat{y_k}$는 모델이 예측한 확률값이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3b3f17380f4883",
   "metadata": {},
   "source": [
    "#### 5. Steepest Gradient Descent & Backpropagation\n",
    "\n",
    "**최대경사법(Steepest Gradient Descent)방법**은 단순히 현재 위치 $x_k$에서의 기울기 값 $g(x_k)$ 만을 이용하여 다음번 위치 $x_{k+1}$를 결정하는 방법이다.\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "x_{k+1} = x_{k} - \\mu \\nabla f(x_k) = x_{k} - \\mu g(x_k) \n",
    "\\tag{5.1.11}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "만약 현재 위치 $x_k$에서 기울기가 음수면 즉 곡면이 아래로 향하면 $g(x_k) < 0$이므로 앞으로 진행하고 현재 위치 $x_k$에서 기울기가 양수면  $g(x_k) > 0$이므로 뒤로 진행하게 되어 점점 낮은 위치로 옮겨간다. 이때 위치를 옮기는 거리를 결정하는 비례상수 $\\mu$를 **스텝 사이즈(step size)**라고 한다. \n",
    "\n",
    "$x_k$가 일단 최적 점에 도달했을 때는 $g(x_k) = 0$이 되므로 더 이상 위치를 옮기지 않는다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ba4788",
   "metadata": {},
   "source": [
    "신경망 학습의 핵심은 **역전파(backpropagation)** 를 통해 가중치를 업데이트하는 것이다. 역전파는 손실 함수의 기울기를 계산하여 가중치를 업데이트하는 방법이다. 이를 위해 **체인 룰(chain rule)** 을 사용한다. 손실 함수에 대한 가중치의 편미분은 다음과 같다.\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial W_{ji}} = \\frac{\\partial L}{\\partial y_k} \\cdot \\frac{\\partial y_k}{\\partial h_j} \\cdot \\frac{\\partial h_j}{\\partial W_{ji}}$$\n",
    "\n",
    "가중치는 역전파와 경사 하강법(gradient descent)을 사용해 업데이트된다\n",
    "\n",
    "$$W_{ji} = W_{ji} - \\eta \\frac{\\partial L}{\\partial W_{ji}}$$\n",
    "\n",
    "여기서 $\\eta$는 학습률(learning rate)이다\n",
    "\n",
    "학습률을 너무 크게 하면, 해가 발산하는 문제가 생기고 너무 작게 하면 학습까지 너무 오래 시간이 걸린다는 문제를 가지고 있다. 따라서 적절한 학습률을 찾아야 한다.\n",
    "\n",
    "<center>\n",
    "\n",
    "![lr.png](Image/learning_rate.png)\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4500e0ad",
   "metadata": {},
   "source": [
    "#### 6. optimizer\n",
    "\n",
    "하지만 경사하강법은 전역 최적해를 잘 찾지 못한다는 문제와, 해가 진동하거나 발산하는 등 적절한 해를 찾지 못한다는 문제점을 가지고 있다.\n",
    "\n",
    "<center>\n",
    "\n",
    "![global.png](Image/global.png)\n",
    "\n",
    "</center>\n",
    "\n",
    "이 문제를 해결하기 위해 다양한 optimization 기법들이 등장한다.\n",
    "\n",
    "1. Stochastic Gradient Descent(SGD) : SGD는 경사하강법과 동일한 방법론을 사용하나, 전체 데이터를 사용하지 않고 미니 배치를 이용해 데이터 세트를 조금씩 훑어보고 가중치를 업데이트 한다. 다른 optimizer보다 단순하고 구현하기 쉽지만 비효율적인 경우가 많다.\n",
    "\n",
    "2. Momentum : Momentum은 경사하강법을 보완한 방법으로, 과거의 진행 방향에 '관성'을 부여해 지역 최적해에서 잘 빠져나오나, 추가적 메모리를 요구하는 단점이 존재한다.\n",
    "\n",
    "$$v_{t+1}=av_t-\\eta \\frac{dL}{dW_t} , \\ W_{t+1}=W_t+v_{t+1}$$\n",
    "\n",
    "3. Nesterov Accelerated Gradient(NAG) : NAG 방식은 Momentum을 기초로 하지만 미리 경사를 확인할 수 있게 하고 경사에 맞춰 속도를 조절한다. Momentum은 현재 위치에서의 기울기와 모멘텀 스텝을 독립적으로 계산하나, NAG 방식은 모멘텀 스텝을 먼저 이동시킨 후 그 위치에서 기울기를 계산한다.\n",
    "\n",
    "4. Adaptive Gradient(AdaGrad) : 이 방법은 학습률을 상수가 아닌 변수값으로 취급해, 학습률을 감소시켜가며 최적해를 빠르고 정확하게 찾을 수 있게 하는 방법이다. 하지만 이 방법은 어느 순간 학습률이 0이 되어 더 이상 학습이 진행되지 않을 가능성이 존재한다는 단점이 있다.\n",
    "\n",
    "5. RMSProp : RMSProp은 AdaGrad의 학습률 감소율을 기울기의 제곱 값이 아닌 기울기의 지수 평균으로 바꾸어 학습률이 0에 수렴하지 않게 만들었다.\n",
    "\n",
    "6. Adaptive Moment Estimation(Adam) : Adam은 RMSProp과 Momentum을 결합한 optimizer이다. 즉, 관성과 학습률 감소법을 모두 적용시킨 optimizer이다\n",
    "\n",
    "7. AdaMax : AdaMax는 Adam가 학습률 조절 방법을 L_2-norm으로 조정하는것을 수정하여 L_p-norm을 사용한다. \n",
    "\n",
    "8. Nadam : Nadam은 NAG와 Adam의 개념을 합친 방법이다. 일반적으로 Adam보다 더 빠르게 전역 최적화값을 찾아낼 수 있다고 알려져 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58493d4a",
   "metadata": {},
   "source": [
    "#### 7. batch size and epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b67a69",
   "metadata": {},
   "source": [
    "딥러닝 과정에서 입력되는 데이터의 사이즈가 커짐에 따라, 전체 데이터를 한번에 모델에 학습시키는 것이 점점 어려워졌다. 또한 한번의 계산으로 최적화된 값을 찾는 것도 쉽지 않은 일이다. 이 문제를 해결하기 위해 Epoch, Batch Size라는 개념이 등장한다.\n",
    "\n",
    "<center>\n",
    "\n",
    "![be.png](Image/batch&epoch.png)\n",
    "\n",
    "</center>\n",
    "\n",
    "Neural Network에서는 계수(Coefficient)보다는 가중치(Weights)로 더 많이 통용된다. 추정하는 가중치 parameter는 결국 선형모형에서 Coefficient를 추정하는것과 같다.\n",
    "\n",
    "**batch size** 는 훈련을 위해 분할한 데이터의 크기를 의미한다. \n",
    "\n",
    "**epoch**는 전체 데이터 셋을 이용해 훈련하는 횟수를 의미한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fe5167",
   "metadata": {},
   "source": [
    "## 딥러닝 모델 구현 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c87e8a0",
   "metadata": {},
   "source": [
    "딥러닝 모델을 구현하기 위한 라이브러리는 크게 pytorch, tensorflow가 있다. 오늘은 tensorflow에서 지원하는 keras를 이용해 딥러닝 모델을 구현하는 방법을 소개한다.\n",
    "\n",
    "keras에서는 `Sequential` 클래스를 이용해 모델을 구현할 수 있다. 좀 더 자세히 설명하면 `Sequential()` 클래스를 바탕으로 입력층부터 은닉층, 출력층까지 순서대로 쌓아갈 수 있다.\n",
    "\n",
    "간단한 에시는 다음과 같다.\n",
    "```python\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(8,kernel_initializer='normal', \n",
    "activation = 'relu', input_dim=len(X.columns)))\n",
    "model.add(Dense(16,kernel_initializer='normal', \n",
    "activation = 'relu', input_dim=len(X.columns)))\n",
    "model.add(Dense(1, kernel_initializer='normal', \n",
    "activation = 'sigmoid'))\n",
    "```\n",
    "이 모델은 입력층, 은닉층, 출력층을 가지는 모델이다. `Sequential`을 사용하면 이렇게 순서대로 층을 쌓아갈 수 있다.\n",
    "\n",
    "모델의 구조를 확인하고 싶다면 `model.summary()`를 사용하면 된다. `model.summary()`에서는 신경망 모델의 구조와 파라미터 정보를 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55950f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kumb2\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m48\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">209</span> (836.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m209\u001b[0m (836.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">209</span> (836.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m209\u001b[0m (836.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(8,kernel_initializer='normal', \n",
    "activation = 'relu', input_dim=5))\n",
    "model.add(Dense(16,kernel_initializer='normal', \n",
    "activation = 'relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal', \n",
    "activation = 'sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f1db07",
   "metadata": {},
   "source": [
    "여기서 \n",
    "\n",
    "- Layer (type): 층의 종류를 나타낸다.\n",
    "- Output Shape: 층의 출력 데이터 형태를 나타낸다. (None, 8)에서 첫 번째 차원인 None은 배치 크기를 의미한다. 이는 한 번에 입력되는 샘플의 개수를 나타내며, 모델을 정의할 때는 알 수 없기 때문에 None으로 표시된다. 나중에 모델을 훈련하거나 예측할 때, 특정 배치 크기 값이 여기에 할당된다. 8은 각 데이터가 8차원의 벡터로 출력된다는 의미이다.\n",
    "- Param #: 층에서 학습해야 할 파라미터의 개수이다. 즉, 모델의 복잡도를 나타내는 지표 중 하나이다.\n",
    "- Total params: 모델 전체의 파라미터 개수이다.\n",
    "- Trainable params: 학습 과정에서 업데이트되는 파라미터의 개수이다.\n",
    "- Non-trainable params: 학습 과정에서 고정되어 있는 파라미터의 개수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a216c4",
   "metadata": {},
   "source": [
    "`Sequential` 외에도 다른 방법이 존재한다. 바로 함수형 API이다. 함수형 API는 이전 층의 노드들이 다음 층의 노드 값을 구하기 위한 입력값으로 사용된다는 점을 이용한 방법이다. 함수형 API를 사용하여 모델을 구성할 때는 입력층과 출력층을 따로 정의하고, 이를 연결하는 층들을 정의하여 모델을 구성한다. 이때는 입력층의 입력값을 모델의 첫 번째 층을 정의할 때 사용한다.\n",
    "\n",
    "위의 모델을 함수형 API를 사용해 구현하면 다음과 같이 구현된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f478dc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m48\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">209</span> (836.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m209\u001b[0m (836.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">209</span> (836.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m209\u001b[0m (836.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "inp = Input(shape=(5,))\n",
    "h1 = Dense(units=8, activation='relu')(inp)\n",
    "h2= Dense(units=16, activation='relu')(h1)\n",
    "out = Dense(units=1, activation='sigmoid')(h2)\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f7576e",
   "metadata": {},
   "source": [
    "Sequential()은 간단한 순차적인 구조를 가진 모델을 쉽게 구성할 수 있어, 초보자들이 쉽게 사용할 수 있다. 하지만, 입력과 출력이 여러 개인 복잡한 모델을 구성하기는 어렵다.\n",
    "반면에 함수형 API는 Sequential()보다 유연하게 모델을 구성할 수 있다. 다중 입력, 다중 출력 등의 복잡한 모델을 쉽게 구성할 수 있다.\n",
    "\n",
    "결론적으로, Sequential()은 간단하고 쉽게 모델을 구성하고 학습할 수 있어 초보자들이 사용하기 적합하다. 반면에 함수형 API는 복잡한 모델 구성에 적합하며, 다양한 네트워크 구조를 구현하기에 용이하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8554fd4",
   "metadata": {},
   "source": [
    "딥러닝 모델의 출력층을 설계할때는 모델의 목적에 맞게 조율을 할 필요가 있다. 예를 들어, 모델의 목적이 회귀인 경우 출력층의 노드는 1개, activation function은 linear(y=x이므로 특별한 activation function을 사용하지 않는 것과 같다)으로 설정해야 한다. \n",
    "\n",
    "회귀모델, 이진분류모델, 다중분류모델의 출력층 설정은 다음 표에 정리되어 있다.\n",
    "\n",
    "<center>\n",
    "\n",
    "![output.png](Image/output_layer.png)\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95154949",
   "metadata": {},
   "source": [
    "모델의 구조를 설정해준 뒤에는 모델을 compile해줘야 한다. 모델을 compile한다는 것은 모델의 손실 함수(loss function), 최적화 방법(optimizer), 평가 지표(metrics)를 설정한다는 의미이다.\n",
    "\n",
    "compile() 메소드의 주요 인자는 다음과 같다.\n",
    ">\n",
    "- optimizer: 최적화 방법을 설정한다. 경사 하강법 등 다양한 최적화 알고리즘 중 하나를 설정하면.\n",
    "- loss: 손실 함수를 설정한다. 모델이 예측한 값과 실제 값 사이의 차이를 계산하는 함수이다.\n",
    "- metrics: 평가 지표를 설정한다. 학습 중 모델의 성능을 평가할 때 사용된다.\n",
    ">\n",
    "\n",
    "이때, loss의 경우  회귀 문제에서는 mean_squared_error, 다중분류 문제에서는 categorical_crossentropy, 이진분류 모델에서는 binary_crossentropy 등이 주로 사용된다. metrics은 회귀 문제에서는 mse나 r_2 score, 분류 문제에서는 accuracy, precision, recall, f1-score, roc-auc 등이 사용된다. 이 또한 모델의 목적에 맞게 잘 설정해줘야 한다.\n",
    "\n",
    "다음은 모델을 compile하는 코드이다.\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb5fce",
   "metadata": {},
   "source": [
    "### example : 집값 예측 딥러닝 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c2fe07795e27f19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:09:25.932691Z",
     "start_time": "2024-09-10T02:09:20.505366Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X, y = datasets.fetch_openml('boston', return_X_y=True)\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63626cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27b6f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DL_price(dropout_rate, verbose=0):\n",
    "    model = keras.Sequential()\n",
    "    model.add(Dense(128,kernel_initializer='normal', \n",
    "        activation = 'relu', input_dim=len(X.columns)))\n",
    "    model.add(Dense(64, kernel_initializer='normal', \n",
    "        activation = 'relu'))\n",
    "    model.add(Dense(8,kernel_initializer='normal', \n",
    "        activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53830b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'batch_size':  [10, 50, 100],\n",
    "          'epochs':  [50, 100, 150],\n",
    "          'dropout_rate' : [0.0, 0.2]}\n",
    "model = KerasRegressor(build_fn = DL_price, dropout_rate=0.1)\n",
    "gs = GridSearchCV(estimator = model,\n",
    "                       param_grid = parameters,\n",
    "                          scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f84c971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Best hyperparameters for first cluster in DL are {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 50}\n"
     ]
    }
   ],
   "source": [
    "gs.fit(X_train, y_train, verbose=0)\n",
    "print('Best hyperparameters for first cluster in DL are {}'.\n",
    "      format(gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dbef63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_2 score is -5.7241\n"
     ]
    }
   ],
   "source": [
    "model = KerasRegressor(build_fn = DL_price,\n",
    "                        dropout_rate = gs.best_params_['dropout_rate'],\n",
    "                        verbose = 0,\n",
    "                        batch_size = gs.best_params_['batch_size'],\n",
    "                        epochs = gs.best_params_['epochs'])\n",
    "model.fit(X_train, y_train)\n",
    "DL_predict = model.predict(X_test)\n",
    "r_2 = r2_score(y_test, pd.DataFrame(DL_predict))\n",
    "print('R_2 score is {:.4f}'.format(r_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01447d4",
   "metadata": {},
   "source": [
    "### practice : 주어진 데이터를 이용해 어느 정당에 투표하였는지 맞추는 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c31dd206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df=pd.read_csv(\"./Data/socioeconomic_voting.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
